{"posts":[{"title":"Win10启用内置Linux子系统（上）","content":"前言 几年前，那会我还在用着崭新的Win7专业版操作系统，但是由于需要学习Linux，因此不得不找了网上的教程：首先下载破解版vmware按照，接着到Ubuntu官网下载镜像文件，然后在安装好的vmware虚拟机中选择镜像文件进行一步一步安装。 但是现在都已经9102年了，对于习惯了开箱即用，用完即走的年轻人来说，这样繁琐的安装过程，显然是乏味的。更何况对于一个Linux初学者来说，他最迫切的需求就是想尽快的感受一下强大的Linux命令行，能像个“黑客”一样坐在电脑前对着黑窗口飞速的敲打键盘... 很幸运，积极拥抱开源世界的微软已经在新版的win10操作系统中内置了Linux（Windows Subsystem for Linux，简称WSL），也就是说，如果你现在电脑用的是新版win10操作系统，你现在就可以快速的体验一下Linux，而不用安装虚拟机等一系列繁琐的步骤。 下面我就带大家一步步启用win10的内置Linux。 首先，在启用或关闭Windows功能中把适用于Linux的Windows子系统选项勾上，步骤如下： 在设置里搜索控制面板: 调整控制面板查看方式为类别，点击程序： 点击启用或关闭Windows功能选项： 在弹出的窗口里找到适用于Linux的Windows子系统选项勾上，然后点击确定按钮，然后重启电脑： 然后，在Microsoft Store中搜索Linux，选择Ubuntu18.04 LTS，点击获取，然后就像手机安装APP一样自动安装： 安装过程中会有一个命令行窗口弹出，如果没有安装失败，该命令行窗口会显示需要给新装的Ubuntu创建一个用户名（该用户名不是root用户），输入你需要起的用户名即可： 紧接着，为你刚刚新建的用户创建密码和确认密码： 至此，你已经在你的win10中安装启动了Ubuntu操作系统，你可以点击开始找到它，也可以固定在任务栏以便快速找到： 然后，你要的命令行黑窗口来了： 后记 总的来说，启用win10中内置的Linux就三个步骤： 勾选适用于Linux的Windows子系统选项； 在Microsoft Store中获取ubuntu安装； 新建用户账号密码。 这确实比在虚拟机中安装方便得多，轻量得多，也优雅得多，强烈建议初学者尝试用这种方式学习Linux。 ","link":"https://githubgavin.github.io/win10-qi-yong-nei-zhi-linux-zi-xi-tong-shang/"},{"title":"Kafka Connect入门","content":"##Kafka Connect简介 Kafka Connect是一个可以在Apache Kafka和其他系统之间进行可伸缩和可靠地传输数据的工具。它使得快速定义将大量数据移入和移出Kafka的Connector变得很简单。Kafka Connect可以摄取整个数据库或将来自所有应用服务器的指标收集到Kafka的topic中，从而使数据能够以低延迟进行流处理。导出作业可以将数据从Kafka topic传递到辅助存储和查询系统，或者传递到批处理系统进行离线分析。 Kafka Connect功能 Kafka连接器的通用框架：Kafka Connect标准化了其他数据系统与Kafka的集成，简化了连接器的开发、部署和管理 单机模式和分布式模式：Kafka Connect启动模式有两种，Standalone（单机模式）和Distribute（分布式模式）。 单机主要用来开发和测试，分布式的用于生产环境。 REST接口：通过一个易于使用的REST API提交和管理到Kafka Connect集群的连接器。 自动偏移管理：只需要很简单的配置 ，Kafka Connect就可以自动管理偏移提交过程，这样连接器开发人员就不必担心连接器开发中的这个容易出错的部分。 分布式和易于伸缩：Kafka Connect建立在现有的组管理协议上。可以添加更多的worker来扩展Kafka连接集群。 流/批处理集成：利用Kafka现有的功能，Kafka Connect是连接流和批处理数据系统的理想解决方案。 运行Kafka Connect自带Demo 前置条件：zookeeper集群和Kafka集群安装启动正常 当你把Kafka集群安装成功后，Kafka Connect也安装好了。由上文可知，Kafka Connect启动方式分为单机模式和分布式模式，现在我们利用Kafka自带Connector分别对这两种模式进行测试。 单机模式： 官网给出的单机模式启动命令： bin/Connect-standalone.sh config/connect-standalone.properties connector1.properties [connector2.properties ...] 如上所示connect-standalone.sh为启动的脚本文件，放在bin目录下；Connect-standalone.properties为单机模式配置文件，放在config目录下；connector1.properties [connector2.properties ...]该处的配置文件为即为Connector配置文件，单机模式下启动可以启动多个Connector。 在测试Demo前需要做少量配置 config/Connect-standalone.properties # 配置Kafka集群地址 bootstrap.servers=localhost:9092 # 配置偏移量保存地址 offset.storage.file.filename=/data/connect-test/connect.offsets config/Connect-file-source.properties # Connector名称 name=local-file-source # Connector类名，可以指定全类名 connector.class=FileStreamSource tasks.max=1 # Connector启动后读取文件的名称 file=/data/connect-test/source.txt # 将读取的文件传到的topic名称 topic=connect-test config/connect-file-sink.properties # Connector名称 name=local-file-sink # Connector类名，可以指定全类名 connector.class=FileStreamSink tasks.max=1 # Connector启动后将Kafka数据保存到的文件名 file=/data/connect-test/sink.txt # 读取数据的topic名称 topics=connect-test 以上文件配置好后，就可以运行Kafka Connect启动命令了： bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties 说明：以上启动两个Connector，其中local-file-source读取/data/connect-test/source.txt的内容，同步到名为connect-test的topic中；local-file-sink读取connect-test的数据写进/data/connect-test/sink.txt文件中。打开source.txt文件往里面实时写数据，保存，sink.txt中能实时的得到数据，从而实现数据在不同文件之间的同步。 分布式模式 官网给出的分布式模式启动命令： bin/connect-distributed.sh config/connect-distributed.properties 分布式模式下，启动命令只有一个配置文件connect-distributed.properties，在进行测试前，同样好做适当的配置 # 配置Kafka集群地址 bootstrap.servers=localhost:9092 # 该topic用于存储偏移量信息 offset.storage.topic=connect-offsets # 该topic用于存储Connector与task的配置信息 config.storage.topic=connect-configs # 该topic用于存储Connector的运行状态信息 status.storage.topic=connect-status 说明：在分布式模式下依赖offset.storage.topic、config.storage.topic、status.storage.topic三个配置，这三个配置项至关重要，如不存在，Kafka会自动创建，但是在实际生产环境中，建议根据业务的数据量手动创建最适合的副本和分区。 执行启动命令后，分布式模式下的Kafka Connect就启动成功了，在分布式模式下，不能用命令行启动Connector，需要用Kafka Connect的rest api来创建，以下用curl命令列举一些常用的rest api方法： # 返回活跃的Connector列表。 curl -i -X GET http://localhost:8083/connectors # 创建一个新的Connector；{请求体}是一个包含字符串name字段和对象config字段（Connector的配置参数）的JSON对象。 curl -H &quot;Accept: application/json&quot; -H &quot;Content-type: application/json&quot; -X POST -d '{请求体}' http://localhost:8083/connectors # 获取指定Connector的信息。 curl -i -X GET http://localhost:8083/connectors/{name} # 获取指定Connector的配置参数。 curl -i -X GET http://localhost:8083/connectors/{name}/config # 获取Connector的当前状态，包括它是否正在运行，失败，暂停等。 curl -i -X GET http://localhost:8083/connectors/{name}/status # 获取当前正在运行的Connector的任务列表。 curl -i -X GET http://localhost:8083/connectors/{name}/tasks 如下所以： root@ZCG04000023:/opt/Kafka_2.11-0.11.0.0/bin# curl -i -X GET http://localhost:8083/connectors HTTP/1.1 200 OK Date: Fri, 11 Oct 2019 09:44:57 GMT Content-Type: application/json Content-Length: 2 Server: Jetty(9.2.15.v20160210) [] 此时还没有任何Connector，返回[]。 创建一个Connector： root@ZCG04000023:/opt/Kafka_2.11-0.11.0.0/bin# curl -H &quot;Accept: application/json&quot; -H &quot;Content-type: application/json&quot; -X POST -d '{&quot;name&quot;:&quot;local-file-source&quot;,&quot;config&quot;:{&quot;connector.class&quot;:&quot;FileStreamSource&quot;,&quot;topic&quot;:&quot;connect-test&quot;,&quot;file&quot;:&quot;/data/connect-test/source.txt&quot;,&quot;tasks.max&quot;:&quot;1&quot;}}' http://localhost:8083/connectors {&quot;name&quot;:&quot;local-file-source&quot;,&quot;config&quot;:{&quot;connector.class&quot;:&quot;FileStreamSource&quot;,&quot;topic&quot;:&quot;connect-test&quot;,&quot;file&quot;:&quot;/data/connect-test/source.txt&quot;,&quot;tasks.max&quot;:&quot;1&quot;,&quot;name&quot;:&quot;local-file-source&quot;},&quot;tasks&quot;:[]} 此时再查看Connector: root@ZCG04000023:/opt/Kafka_2.11-0.11.0.0/bin# curl -i -X GET http://localhost:8083/connectors HTTP/1.1 200 OK Date: Fri, 11 Oct 2019 10:00:02 GMT Content-Type: application/json Content-Length: 21 Server: Jetty(9.2.15.v20160210) [&quot;local-file-source&quot;] 看到已经成功创建了一个名为local-file-source的Connector。 获取local-file-source的信息： root@ZCG04000023:/opt/Kafka_2.11-0.11.0.0/bin# curl -i -X GET http://localhost:8083/connectors/local-file-source HTTP/1.1 200 OK Date: Fri, 11 Oct 2019 10:08:05 GMT Content-Type: application/json Content-Length: 234 Server: Jetty(9.2.15.v20160210) {&quot;name&quot;:&quot;local-file-source&quot;,&quot;config&quot;:{&quot;connector.class&quot;:&quot;FileStreamSource&quot;,&quot;file&quot;:&quot;/data/connect-test/source.txt&quot;,&quot;tasks.max&quot;:&quot;1&quot;,&quot;name&quot;:&quot;local-file-source&quot;,&quot;topic&quot;:&quot;connect-test&quot;},&quot;tasks&quot;:[{&quot;connector&quot;:&quot;local-file-source&quot;,&quot;task&quot;:0}]} 用同样的方式创建local-file-sink： root@ZCG04000023:/opt/Kafka_2.11-0.11.0.0/bin# curl -H &quot;Accept: application/json&quot; -H &quot;Content-type: application/json&quot; -X POST -d '{&quot;name&quot;:&quot;local-file-sink&quot;,&quot;config&quot;:{&quot;connector.class&quot;:&quot;FileStreamSink&quot;,&quot;topic&quot;:&quot;connect-test&quot;,&quot;file&quot;:&quot;/data/connect-test/sink.txt&quot;,&quot;tasks.max&quot;:&quot;1&quot;}}' http://localhost:8083/connectors {&quot;name&quot;:&quot;local-file-sink&quot;,&quot;config&quot;:{&quot;connector.class&quot;:&quot;FileStreamSink&quot;,&quot;topic&quot;:&quot;connect-test&quot;,&quot;file&quot;:&quot;/data/connect-test/sink.txt&quot;,&quot;tasks.max&quot;:&quot;1&quot;,&quot;name&quot;:&quot;local-file-sink&quot;},&quot;tasks&quot;:[]} source和sink创建好之后，就可以测试利用Kafka Connect的分布式模式实现文件的同步了。 至此，我们已经初步了解了Kafka Connect的概念以及对其功能进行了简单的测试，下一步我们将对其Connector、task等组件进行分析。 ","link":"https://githubgavin.github.io/kafka-connect/"}]}