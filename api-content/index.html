{"posts":[{"title":"Win10启用内置Linux子系统（下）","content":"看完上一篇文章后，相信勤于动手操作的你，已经启用了win10内置的Linux系统（以下简称wsl），或许你已经在上面尝试了不少Linux命令，并且可能沉浸在命令行的交互中流连忘返。但是细心如你应该会发现：此时你是用你在安装时新建的普通用户登录的，并不知道root用户的密码；怎样才能在不重启电脑的情况下重启wsl；当你输入df -h命令查看磁盘空间时会看到类似/mnt/c、/mnt/d这样的目录；在secureCRT或Xshell工具无法用账号密码登录Linux系统...诸如此类的问题，我们现在就把它解决。 1，设置Linux系统root用户密码 在你安装wsl过程中，并没有任何设置root密码的提示，默认情况下在每次开机系统就会为root用户随机分配一个新密码，因此我们要为root用户初始化一个密码。 首先在命令行输入sudo passwd，输入当前用户密码，按Enter键，出现Enter new UNIX password的提示，这就是需要为root用户设置的密码，输入一个你想好的密码，按Enter键，接着出现Retype new UNIX password提示，再把刚才的密码输入一遍即可。当你看到successfully时说明你的root密码设置成功了，接着可以输入su - root，按Enter键，输入root密码登录系统。具体如下所示： gavin@ZCG04000023:~$ sudo passwd [sudo] password for gavin: Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully gavin@ZCG04000023:~$ su - root Password: root@ZCG04000023:~# 2，重启wsl 从Windows Subsystem for Linux这个名字我们就可以看出，wsl作为Windows操作系统下的应用级别程序，并没有把systemd纳入进来，因此我们无法用reboot命令进行系统重启。如果在Linux子系统下更改了某些配置需要重启才能生效的，该如何处理呢？难道要重启电脑吗？当然不用，可以到Windows服务中通过重启Lxssmanager实现wsl的重启，步骤如下： 按Win键 + R，在弹出的框中输入services.msc，按Enter键即可弹出Windows服务窗口，找到Lxssmanager，右键，选择“重新启动”即可。 3，将挂载在mnt目录下的磁盘修改成挂载在根目录 mnt为mount（可翻译为“挂载”）的简写，mnt作为Linux系统的一个目录，是系统管理员临时挂载文件系统的安装点，程序并不自动支持安装到/mnt目录下。当你在命令行中敲下df -h时你会看到类似如下内容： gavin@ZCG04000023:~$ df -h Filesystem Size Used Avail Use% Mounted on rootfs 84G 58G 27G 69% / none 84G 58G 27G 69% /dev none 84G 58G 27G 69% /run none 84G 58G 27G 69% /run/lock none 84G 58G 27G 69% /run/shm none 84G 58G 27G 69% /run/user C: 84G 58G 27G 69% /mnt/c D: 141G 63G 78G 45% /mnt/d 当然，你也可以忽略它，mnt的存在并不妨碍你学习Linux命令，但是改为直接挂载在根目录下，除了目录名短一点外，在后面学习docker共享目录时，这个mnt的存在可能会影响到docker目录的挂载，所以还是及早的改好。修改也是简单的事，执行命令sudo vim /etc/wsl.conf，输入密码，如果wsl.conf不存在时，该命令会新建一个。接着在文件里填上以下内容：（按i进入编辑模式） [automount] root = / options = &quot;metadata&quot; 按exc键退出编辑模式，然后按shift + ：，再按wq，按Enter，就能保存并退出了。更改需要重启wsl才能生效。按照重启步骤重启后，我们再输入df -h命令，将会看到已经把mnt去掉了： gavin@ZCG04000023:~$ df -h Filesystem Size Used Avail Use% Mounted on rootfs 84G 58G 27G 69% / none 84G 58G 27G 69% /dev none 84G 58G 27G 69% /run none 84G 58G 27G 69% /run/lock none 84G 58G 27G 69% /run/shm none 84G 58G 27G 69% /run/user C: 84G 58G 27G 69% /c D: 141G 63G 78G 45% /d PS:以上步骤中涉及到的vim的语法如果不熟悉，建议到到网上找vim相关文章参考，以下是vim 键盘图 。 图片来自Linux vi/vim | 菜鸟教程 4，使用secureCRT/Xshell客户端登录wsl 当你在Windows中启用wsl成功后，系统会有一个Linux shell终端可以让你连上wsl进行命令操作，一般说来，这个Linux shell是能work（堪用）的，但是对于品味挑剔的你来说，自带的Linux shell功能还是不够强大：不能在一个窗口打开多个tab页，不能设置多个连接记录，不能设置快捷键，更没有你喜欢的花俏的皮肤和背景...这些理由，足以让你果断摈弃Linux shell，迫不及待的把secureCRT、Xshell装上。接下来就是示范如何使用secureCRT客户端登录wsl。 利用secureCRT登录wsl需要wsl启动ssh服务，前提是把ssh服务安装到wsl上，在命令行中执行以下命令，即可把ssh服务安装好。 sudo apt-get update #获取软件的最新状态 sudo apt-get remove openssh-server #卸载自带的ssh sudo apt-get install -y openssh-server #安装ssh服务 ssh服务安装好之后，需要进行配置才能利用账号密码登录，否则需要ssh证书验证，修改sshd_config文件可以允许用户采用密码登录。 sudo vim /etc/ssh/sshd_config # To disable tunneled clear text passwords, change to no here! PasswordAuthentication yes #打开这个注释，即可允许用户用密码方式登录 修改好后保存、退出，执行命令sudo service ssh start启动ssh服务 gavin@ZCG04000023:~$ sudo service ssh start * Starting OpenBSD Secure Shell server sshd [ OK ] gavin@ZCG04000023:~$ sudo service ssh status查看ssh服务状态 gavin@ZCG04000023:~$ sudo service ssh status * sshd is running gavin@ZCG04000023:~$ 现在可以用secureCRT登录wsl了，首先得把secureCRT安装好，文末有软件共享地址。启动secureCRT，按照下图步骤配置： 在弹出的框中填写密码，建议把Save password选项勾上，点击ok 连接成功后如下图所示： PS：目前ssh服务是wsl启动后通过service ssh start手动启动的，对于如何设置ssh服务开机启动，可以参考文末GitHub地址。 secureCRT下载： https://pan.baidu.com/s/1rw_xm6uNhfRLNiUlChqt8Q 提取码：tw7z wsl-autostart地址： https://github.com/troytse/wsl-autostart ","link":"https://githubgavin.github.io/kafka-connect-2/"},{"title":"Win10启用内置Linux子系统（上）","content":"前言 几年前，那会我还在用着崭新的Win7专业版操作系统，但是由于需要学习Linux，因此不得不找了网上的教程：首先下载破解版vmware按照，接着到Ubuntu官网下载镜像文件，然后在安装好的vmware虚拟机中选择镜像文件进行一步一步安装。 但是现在都已经9102年了，对于习惯了开箱即用，用完即走的年轻人来说，这样繁琐的安装过程，显然是乏味的。更何况对于一个Linux初学者来说，他最迫切的需求就是想尽快的感受一下强大的Linux命令行，能像个“黑客”一样坐在电脑前对着黑窗口飞速的敲打键盘... 很幸运，积极拥抱开源世界的微软已经在新版的win10操作系统中内置了Linux（Windows Subsystem for Linux，简称WSL），也就是说，如果你现在电脑用的是新版win10操作系统，你现在就可以快速的体验一下Linux，而不用安装虚拟机等一系列繁琐的步骤。 下面我就带大家一步步启用win10的内置Linux。 首先，在启用或关闭Windows功能中把适用于Linux的Windows子系统选项勾上，步骤如下： 在设置里搜索控制面板: 调整控制面板查看方式为类别，点击程序： 点击启用或关闭Windows功能选项： 在弹出的窗口里找到适用于Linux的Windows子系统选项勾上，然后点击确定按钮，然后重启电脑： 然后，在Microsoft Store中搜索Linux，选择Ubuntu18.04 LTS，点击获取，然后就像手机安装APP一样自动安装： 安装过程中会有一个命令行窗口弹出，如果没有安装失败，该命令行窗口会显示需要给新装的Ubuntu创建一个用户名（该用户名不是root用户），输入你需要起的用户名即可： 紧接着，为你刚刚新建的用户创建密码和确认密码： 至此，你已经在你的win10中安装启动了Ubuntu操作系统，你可以点击开始找到它，也可以固定在任务栏以便快速找到： 然后，你要的命令行黑窗口来了： 后记 总的来说，启用win10中内置的Linux就三个步骤： 勾选适用于Linux的Windows子系统选项； 在Microsoft Store中获取ubuntu安装； 新建用户账号密码。 这确实比在虚拟机中安装方便得多，轻量得多，也优雅得多，强烈建议初学者尝试用这种方式学习Linux。 ","link":"https://githubgavin.github.io/win10-qi-yong-nei-zhi-linux-zi-xi-tong-shang/"},{"title":"Kafka Connect入门","content":"Kafka Connect简介 Kafka Connect是一个可以在Apache Kafka和其他系统之间进行可伸缩和可靠地传输数据的工具。它使得快速定义将大量数据移入和移出Kafka的Connector变得很简单。Kafka Connect可以摄取整个数据库或将来自所有应用服务器的指标收集到Kafka的topic中，从而使数据能够以低延迟进行流处理。导出作业可以将数据从Kafka topic传递到辅助存储和查询系统，或者传递到批处理系统进行离线分析。 Kafka Connect功能 Kafka连接器的通用框架：Kafka Connect标准化了其他数据系统与Kafka的集成，简化了连接器的开发、部署和管理 单机模式和分布式模式：Kafka Connect启动模式有两种，Standalone（单机模式）和Distribute（分布式模式）。 单机主要用来开发和测试，分布式的用于生产环境。 REST接口：通过一个易于使用的REST API提交和管理到Kafka Connect集群的连接器。 自动偏移管理：只需要很简单的配置 ，Kafka Connect就可以自动管理偏移提交过程，这样连接器开发人员就不必担心连接器开发中的这个容易出错的部分。 分布式和易于伸缩：Kafka Connect建立在现有的组管理协议上。可以添加更多的worker来扩展Kafka连接集群。 流/批处理集成：利用Kafka现有的功能，Kafka Connect是连接流和批处理数据系统的理想解决方案。 运行Kafka Connect自带Demo 前置条件：zookeeper集群和Kafka集群安装启动正常 当你把Kafka集群安装成功后，Kafka Connect也安装好了。由上文可知，Kafka Connect启动方式分为单机模式和分布式模式，现在我们利用Kafka自带Connector分别对这两种模式进行测试。 单机模式： 官网给出的单机模式启动命令： bin/Connect-standalone.sh config/connect-standalone.properties connector1.properties [connector2.properties ...] 如上所示connect-standalone.sh为启动的脚本文件，放在bin目录下；Connect-standalone.properties为单机模式配置文件，放在config目录下；connector1.properties [connector2.properties ...]该处的配置文件为即为Connector配置文件，单机模式下启动可以启动多个Connector。 在测试Demo前需要做少量配置 config/Connect-standalone.properties # 配置Kafka集群地址 bootstrap.servers=localhost:9092 # 配置偏移量保存地址 offset.storage.file.filename=/data/connect-test/connect.offsets config/Connect-file-source.properties # Connector名称 name=local-file-source # Connector类名，可以指定全类名 connector.class=FileStreamSource tasks.max=1 # Connector启动后读取文件的名称 file=/data/connect-test/source.txt # 将读取的文件传到的topic名称 topic=connect-test config/connect-file-sink.properties # Connector名称 name=local-file-sink # Connector类名，可以指定全类名 connector.class=FileStreamSink tasks.max=1 # Connector启动后将Kafka数据保存到的文件名 file=/data/connect-test/sink.txt # 读取数据的topic名称 topics=connect-test 以上文件配置好后，就可以运行Kafka Connect启动命令了： bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties 说明：以上启动两个Connector，其中local-file-source读取/data/connect-test/source.txt的内容，同步到名为connect-test的topic中；local-file-sink读取connect-test的数据写进/data/connect-test/sink.txt文件中。打开source.txt文件往里面实时写数据，保存，sink.txt中能实时的得到数据，从而实现数据在不同文件之间的同步。 分布式模式 官网给出的分布式模式启动命令： bin/connect-distributed.sh config/connect-distributed.properties 分布式模式下，启动命令只有一个配置文件connect-distributed.properties，在进行测试前，同样好做适当的配置 # 配置Kafka集群地址 bootstrap.servers=localhost:9092 # 该topic用于存储偏移量信息 offset.storage.topic=connect-offsets # 该topic用于存储Connector与task的配置信息 config.storage.topic=connect-configs # 该topic用于存储Connector的运行状态信息 status.storage.topic=connect-status 说明：在分布式模式下依赖offset.storage.topic、config.storage.topic、status.storage.topic三个配置，这三个配置项至关重要，如不存在，Kafka会自动创建，但是在实际生产环境中，建议根据业务的数据量手动创建最适合的副本和分区。 执行启动命令后，分布式模式下的Kafka Connect就启动成功了，在分布式模式下，不能用命令行启动Connector，需要用Kafka Connect的rest api来创建，以下用curl命令列举一些常用的rest api方法： # 返回活跃的Connector列表。 curl -i -X GET http://localhost:8083/connectors # 创建一个新的Connector；{请求体}是一个包含字符串name字段和对象config字段（Connector的配置参数）的JSON对象。 curl -H &quot;Accept: application/json&quot; -H &quot;Content-type: application/json&quot; -X POST -d '{请求体}' http://localhost:8083/connectors # 获取指定Connector的信息。 curl -i -X GET http://localhost:8083/connectors/{name} # 获取指定Connector的配置参数。 curl -i -X GET http://localhost:8083/connectors/{name}/config # 获取Connector的当前状态，包括它是否正在运行，失败，暂停等。 curl -i -X GET http://localhost:8083/connectors/{name}/status # 获取当前正在运行的Connector的任务列表。 curl -i -X GET http://localhost:8083/connectors/{name}/tasks 如下所以： root@ZCG04000023:/opt/Kafka_2.11-0.11.0.0/bin# curl -i -X GET http://localhost:8083/connectors HTTP/1.1 200 OK Date: Fri, 11 Oct 2019 09:44:57 GMT Content-Type: application/json Content-Length: 2 Server: Jetty(9.2.15.v20160210) [] 此时还没有任何Connector，返回[]。 创建一个Connector： root@ZCG04000023:/opt/Kafka_2.11-0.11.0.0/bin# curl -H &quot;Accept: application/json&quot; -H &quot;Content-type: application/json&quot; -X POST -d '{&quot;name&quot;:&quot;local-file-source&quot;,&quot;config&quot;:{&quot;connector.class&quot;:&quot;FileStreamSource&quot;,&quot;topic&quot;:&quot;connect-test&quot;,&quot;file&quot;:&quot;/data/connect-test/source.txt&quot;,&quot;tasks.max&quot;:&quot;1&quot;}}' http://localhost:8083/connectors {&quot;name&quot;:&quot;local-file-source&quot;,&quot;config&quot;:{&quot;connector.class&quot;:&quot;FileStreamSource&quot;,&quot;topic&quot;:&quot;connect-test&quot;,&quot;file&quot;:&quot;/data/connect-test/source.txt&quot;,&quot;tasks.max&quot;:&quot;1&quot;,&quot;name&quot;:&quot;local-file-source&quot;},&quot;tasks&quot;:[]} 此时再查看Connector: root@ZCG04000023:/opt/Kafka_2.11-0.11.0.0/bin# curl -i -X GET http://localhost:8083/connectors HTTP/1.1 200 OK Date: Fri, 11 Oct 2019 10:00:02 GMT Content-Type: application/json Content-Length: 21 Server: Jetty(9.2.15.v20160210) [&quot;local-file-source&quot;] 看到已经成功创建了一个名为local-file-source的Connector。 获取local-file-source的信息： root@ZCG04000023:/opt/Kafka_2.11-0.11.0.0/bin# curl -i -X GET http://localhost:8083/connectors/local-file-source HTTP/1.1 200 OK Date: Fri, 11 Oct 2019 10:08:05 GMT Content-Type: application/json Content-Length: 234 Server: Jetty(9.2.15.v20160210) {&quot;name&quot;:&quot;local-file-source&quot;,&quot;config&quot;:{&quot;connector.class&quot;:&quot;FileStreamSource&quot;,&quot;file&quot;:&quot;/data/connect-test/source.txt&quot;,&quot;tasks.max&quot;:&quot;1&quot;,&quot;name&quot;:&quot;local-file-source&quot;,&quot;topic&quot;:&quot;connect-test&quot;},&quot;tasks&quot;:[{&quot;connector&quot;:&quot;local-file-source&quot;,&quot;task&quot;:0}]} 用同样的方式创建local-file-sink： root@ZCG04000023:/opt/Kafka_2.11-0.11.0.0/bin# curl -H &quot;Accept: application/json&quot; -H &quot;Content-type: application/json&quot; -X POST -d '{&quot;name&quot;:&quot;local-file-sink&quot;,&quot;config&quot;:{&quot;connector.class&quot;:&quot;FileStreamSink&quot;,&quot;topic&quot;:&quot;connect-test&quot;,&quot;file&quot;:&quot;/data/connect-test/sink.txt&quot;,&quot;tasks.max&quot;:&quot;1&quot;}}' http://localhost:8083/connectors {&quot;name&quot;:&quot;local-file-sink&quot;,&quot;config&quot;:{&quot;connector.class&quot;:&quot;FileStreamSink&quot;,&quot;topic&quot;:&quot;connect-test&quot;,&quot;file&quot;:&quot;/data/connect-test/sink.txt&quot;,&quot;tasks.max&quot;:&quot;1&quot;,&quot;name&quot;:&quot;local-file-sink&quot;},&quot;tasks&quot;:[]} source和sink创建好之后，就可以测试利用Kafka Connect的分布式模式实现文件的同步了。 至此，我们已经初步了解了Kafka Connect的概念以及对其功能进行了简单的测试，下一步我们将对其Connector、task等组件进行分析。 ","link":"https://githubgavin.github.io/kafka-connect/"}]}